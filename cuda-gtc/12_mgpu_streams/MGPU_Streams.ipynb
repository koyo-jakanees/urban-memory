{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Copy Compute Overlap with Multiple GPUs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn the indexing strategies required to combine the techniques you have learned so far and apply copy/compute overlap when using multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will understand:\n",
    "\n",
    "* How streams are associated with each GPU device\n",
    "* How to create non-default streams for multiple GPUs\n",
    "* How to perform copy/compute overlap on multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Streams and Multiple GPUs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each GPU has its own default stream. Non-default streams can be created, utilized, and destroyed for the currently active GPU device. Care must be taken not to launch kernels in streams not associated with the currently active GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Creating Multiple Streams for Multiple GPUs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using multiple non-default streams on multiple GPUs, rather than simply store streams in an array as we did previously, we will store them in a 2D array, with each row containing the streams for a single GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t streams[num_gpus][num_streams]; // 2D array containing number of streams for each GPU.\n",
    "\n",
    "// For each available GPU...\n",
    "for (uint64_t gpu = 0; gpu < num_gpus; gpu++) {\n",
    "    // ...set as active device...\n",
    "    cudaSetDevice(gpu);\n",
    "    for (uint64_t stream = 0; stream < num_streams; stream++)\n",
    "        // ...create and store its number of streams.\n",
    "        cudaStreamCreate(&streams[gpu][stream]);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Data Chunk Sizes for Multiple Streams on Multiple GPUs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing into global data becomes even more tricky when using multiple non-default streams with multiple GPUs. It can be helpful to define data chunk sizes for a single stream, as well as data chunk sizes for an entire GPU. Here we will continue to use the robust indexing strategies discussed in [Copy Compute Considerations](../08_Copy_Compute_Considerations/Copy_Compute_Considerations.ipynb):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// Each stream needs num_entries/num_gpus/num_streams data. We use round up division for\n",
    "// reasons previously discussed.\n",
    "const uint64_t stream_chunk_size = sdiv(sdiv(num_entries, num_gpus), num_streams);\n",
    "\n",
    "// It will be helpful to also to have handy the chunk size for an entire GPU.\n",
    "const uint64_t gpu_chunk_size = stream_chunk_size*num_streams;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Allocating Memory with Multiple Streams for Multiple GPUs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU memory is not allocated with streams, so allocation here looks similar to our previous work with multiple GPUs, only care needs to be taken to use a chunk size for the entire GPU, and not one of its streams:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// For each GPU...\n",
    "for (uint64_t gpu = 0; gpu < num_gpus; gpu++) {\n",
    "\n",
    "    // ...set device as active...\n",
    "    cudaSetDevice(gpu);\n",
    "\n",
    "    // ...use a GPU chunk's worth of data to calculate indices and width...\n",
    "    const uint64_t lower = gpu_chunk_size*gpu;\n",
    "    const uint64_t upper = min(lower+gpu_chunk_size, num_entries);\n",
    "    const uint64_t width = upper-lower;\n",
    "\n",
    "    // ...allocate data.\n",
    "    cudaMalloc(&data_gpu[gpu], sizeof(uint64_t)*width);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Copy/Compute Overlap with Multiple Streams for Multiple GPUs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each GPU, we will perform copy/compute overlap in multiple non-default streams. This technique is very similar as that with only one GPU, only we must do it while looping over each GPU, and, take some additional care with indexing into the data. Work through this section slowly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// For each GPU...\n",
    "for (uint64_t gpu = 0; gpu < num_gpus; gpu++) {\n",
    "    // ...set device as active.\n",
    "    cudaSetDevice(gpu);\n",
    "    // For each stream (on each GPU)...\n",
    "    for (uint64_t stream = 0; stream < num_streams; stream++) {\n",
    "\n",
    "        // Calculate index offset for this stream's chunk of data within the GPU's chunk of data...\n",
    "        const uint64_t stream_offset = stream_chunk_size*stream;\n",
    "        \n",
    "        // ...get the lower index within all data, and width of this stream's data chunk...\n",
    "        const uint64_t lower = gpu_chunk_size*gpu+stream_offset;\n",
    "        const uint64_t upper = min(lower+stream_chunk_size, num_entries);\n",
    "        const uint64_t width = upper-lower;\n",
    "\n",
    "        // ...perform async HtoD memory copy...\n",
    "        cudaMemcpyAsync(data_gpu[gpu]+stream_offset, // This stream's data within this GPU's data.\n",
    "                        data_cpu+lower,              // This stream's data within all CPU data.\n",
    "                        sizeof(uint64_t)*width,      // This stream's chunk size worth of data.\n",
    "                        cudaMemcpyHostToDevice,\n",
    "                        streams[gpu][stream]);       // Using this stream for this GPU.\n",
    "\n",
    "        kernel<<<grid, block, 0, streams[gpu][stream]>>>    // Using this stream for this GPU.\n",
    "            (data_gpu[gpu]+stream_offset,                   // This stream's data within this GPU's data.\n",
    "             width);                                        // This stream's chunk size worth of data.\n",
    "\n",
    "        cudaMemcpyAsync(data_cpu+lower,              // This stream's data within all CPU data.\n",
    "                        data_gpu[gpu]+stream_offset, // This stream's data within this GPU's data.\n",
    "                        sizeof(uint64_t)*width,\n",
    "                        cudaMemcpyDeviceToHost,\n",
    "                        streams[gpu][stream]);       // Using this stream for this GPU.\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Check for Understanding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the following to confirm you've learned the main objectives of this section. You can display the answers for each question by clicking on the \"...\" cells below the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the following is true? Choose all that apply.**\n",
    "\n",
    "1. The default stream is reserved for the GPU device with index `0`\n",
    "2. Each GPU has its own default stream\n",
    "3. Non-default streams can be created for the currently active GPU\n",
    "4. A single non-default stream can be used to perform operations on multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Answer: 2, 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernels can be launched on a not-currently-active GPU by launching it in a stream associated with a not-currently-active GPU.**\n",
    "\n",
    "1. True\n",
    "2. False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Answer: 2**\n",
    "\n",
    "Kernel launches will fail if issued into a stream not associated with the currently active GPU device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all the techniques at your disposal needed to perform copy/compute overlap on multiple GPUs. In the next section you will once again refactor the cipher application, this time for tremendous speedups by performing copy/compute overlap while doing computations on multiple GPUs.\n",
    "\n",
    "Please continue to the next section: [*Exercise: MGPU Streams*](../13_Exercise_MGPU_Streams/Exercise_MGPU_Streams.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
